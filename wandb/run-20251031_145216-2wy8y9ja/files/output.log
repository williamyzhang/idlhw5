10/31/2025 14:52:17 - INFO - __main__ - ***** Training arguments *****
10/31/2025 14:52:17 - INFO - __main__ - Namespace(config='configs/ddpm.yaml', data_dir='./data', image_size=128, batch_size=32, num_workers=4, num_classes=100, run_name='exp-0-ddpm', output_dir='experiments', num_epochs=20, learning_rate=0.001, weight_decay=0.01, grad_clip=1.0, seed=42, mixed_precision='none', num_train_timesteps=1000, num_inference_steps=250, beta_start=0.0001, beta_end=0.02, beta_schedule='linear', variance_type='fixed_small', prediction_type='epsilon', clip_sample=True, clip_sample_range=1.0, unet_in_size=128, unet_in_ch=3, unet_ch=128, unet_ch_mult=[1, 2, 2, 4], unet_attn=[2, 3], unet_num_res_blocks=2, unet_dropout=0.1, latent_ddpm=False, use_cfg=False, cfg_guidance_scale=2.0, use_ddim=False, use_cifar10=True, ckpt=None, distributed=False, world_size=1, rank=0, local_rank=0, device='cuda', total_batch_size=32, max_train_steps=31260)
10/31/2025 14:52:17 - INFO - __main__ - ***** Running training *****
10/31/2025 14:52:17 - INFO - __main__ -   Num examples = 50000
10/31/2025 14:52:17 - INFO - __main__ -   Num Epochs = 20
10/31/2025 14:52:17 - INFO - __main__ -   Instantaneous batch size per device = 32
10/31/2025 14:52:17 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 32
10/31/2025 14:52:17 - INFO - __main__ -   Total optimization steps per epoch 1563
10/31/2025 14:52:17 - INFO - __main__ -   Total optimization steps = 31260
  0%|                                                                       | 0/31260 [00:00<?, ?it/s]10/31/2025 14:52:17 - INFO - __main__ - Epoch 1/20
  0%|                                                             | 1/31260 [00:00<5:27:37,  1.59it/s]10/31/2025 14:52:18 - INFO - __main__ - Epoch 1/20, Step 0/1563, Loss 0.995053768157959 (0.995053768157959)
  0%|▏                                                            | 101/31260 [00:11<58:26,  8.89it/s]10/31/2025 14:52:29 - INFO - __main__ - Epoch 1/20, Step 100/1563, Loss 1.0086082220077515 (1.0002860291169422)
  1%|▍                                                            | 201/31260 [00:23<58:10,  8.90it/s]10/31/2025 14:52:40 - INFO - __main__ - Epoch 1/20, Step 200/1563, Loss 0.9854004383087158 (0.9975170997244802)
  1%|▌                                                            | 301/31260 [00:34<57:58,  8.90it/s]10/31/2025 14:52:51 - INFO - __main__ - Epoch 1/20, Step 300/1563, Loss 0.9347564578056335 (0.9875496720950865)
  1%|▊                                                            | 401/31260 [00:45<57:50,  8.89it/s]10/31/2025 14:53:03 - INFO - __main__ - Epoch 1/20, Step 400/1563, Loss 0.8850607872009277 (0.9686473960293795)
  2%|▉                                                            | 501/31260 [00:56<57:33,  8.91it/s]10/31/2025 14:53:14 - INFO - __main__ - Epoch 1/20, Step 500/1563, Loss 0.8312777876853943 (0.9445375687109971)
  2%|█▏                                                           | 601/31260 [01:08<57:27,  8.89it/s]10/31/2025 14:53:25 - INFO - __main__ - Epoch 1/20, Step 600/1563, Loss 0.9995088577270508 (0.93792145026107)
  2%|█▎                                                           | 701/31260 [01:19<57:14,  8.90it/s]10/31/2025 14:53:36 - INFO - __main__ - Epoch 1/20, Step 700/1563, Loss 1.0011839866638184 (0.9467433850877466)
  3%|█▌                                                           | 801/31260 [01:30<57:04,  8.89it/s]10/31/2025 14:53:48 - INFO - __main__ - Epoch 1/20, Step 800/1563, Loss 0.9944796562194824 (0.9533930357624678)
  3%|█▊                                                           | 901/31260 [01:41<56:54,  8.89it/s]10/31/2025 14:53:59 - INFO - __main__ - Epoch 1/20, Step 900/1563, Loss 1.0027544498443604 (0.9585021605899146)
  3%|█▉                                                          | 1001/31260 [01:53<56:38,  8.90it/s]10/31/2025 14:54:10 - INFO - __main__ - Epoch 1/20, Step 1000/1563, Loss 0.9975308179855347 (0.9626085829067897)
  4%|██                                                          | 1101/31260 [02:04<56:27,  8.90it/s]10/31/2025 14:54:21 - INFO - __main__ - Epoch 1/20, Step 1100/1563, Loss 0.999000072479248 (0.965996732666317)
  4%|██▎                                                         | 1201/31260 [02:15<56:18,  8.90it/s]10/31/2025 14:54:33 - INFO - __main__ - Epoch 1/20, Step 1200/1563, Loss 0.996706485748291 (0.9686970371787097)
  4%|██▍                                                         | 1301/31260 [02:26<56:11,  8.89it/s]10/31/2025 14:54:44 - INFO - __main__ - Epoch 1/20, Step 1300/1563, Loss 0.9996668696403503 (0.9709311534953429)
  4%|██▋                                                         | 1401/31260 [02:38<55:59,  8.89it/s]10/31/2025 14:54:55 - INFO - __main__ - Epoch 1/20, Step 1400/1563, Loss 1.0014855861663818 (0.9727273548100354)
  5%|██▉                                                         | 1501/31260 [02:49<55:49,  8.89it/s]10/31/2025 14:55:06 - INFO - __main__ - Epoch 1/20, Step 1500/1563, Loss 0.9930121302604675 (0.9742663705213954)
  5%|██▉                                                       | 1563/31260 [02:56<1:03:10,  7.83it/s]Traceback (most recent call last):
  File "/jet/home/wzhang31/hw5_student_starter_code/train.py", line 406, in <module>
    main()
  File "/jet/home/wzhang31/hw5_student_starter_code/train.py", line 386, in main
    gen_images = pipeline(None)
  File "/ocean/projects/cis250019p/mzhang23/TA/HW2P2/envs/hw2p2_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/jet/home/wzhang31/hw5_student_starter_code/pipelines/ddpm.py", line 90, in __call__
    image = randn_tensor(image_shape, generator=generator, device=device)
  File "/jet/home/wzhang31/hw5_student_starter_code/utils/misc.py", line 57, in randn_tensor
    latents = torch.randn(shape, generator=generator, device=rand_device, dtype=dtype, layout=layout).to(device)
TypeError: randn() received an invalid combination of arguments - got (tuple, layout=torch.layout, dtype=NoneType, device=torch.device, generator=NoneType), but expected one of:
 * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, *, torch.Generator generator, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

Traceback (most recent call last):
  File "/jet/home/wzhang31/hw5_student_starter_code/train.py", line 406, in <module>
    main()
  File "/jet/home/wzhang31/hw5_student_starter_code/train.py", line 386, in main
    gen_images = pipeline(None)
  File "/ocean/projects/cis250019p/mzhang23/TA/HW2P2/envs/hw2p2_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/jet/home/wzhang31/hw5_student_starter_code/pipelines/ddpm.py", line 90, in __call__
    image = randn_tensor(image_shape, generator=generator, device=device)
  File "/jet/home/wzhang31/hw5_student_starter_code/utils/misc.py", line 57, in randn_tensor
    latents = torch.randn(shape, generator=generator, device=rand_device, dtype=dtype, layout=layout).to(device)
TypeError: randn() received an invalid combination of arguments - got (tuple, layout=torch.layout, dtype=NoneType, device=torch.device, generator=NoneType), but expected one of:
 * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, *, torch.Generator generator, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
